# Evaluation: GPT-4o-mini L-MENTHOL Test Result

## ğŸ“Š Overall Assessment: **PARTIAL CHEATING DETECTED** âš ï¸

Score: **6.5/10** - Model is partially following instructions but still copying some template values

---

## âœ… What GPT-4o-mini Got RIGHT:

### 1. **NOAEL Value** âœ… CORRECT
```json
"value": 200
```
**Analysis**: âœ… Correctly extracted 200 from instruction (not 800 from PETROLATUM example)

### 2. **INCI Name** âœ… CORRECT
```json
"inci": "L-MENTHOL"
```
**Analysis**: âœ… Correctly used L-MENTHOL (not PETROLATUM)

### 3. **Source** âœ… CORRECT
```json
"source": "oecd_sids_menthols_unep_publications"
```
**Analysis**: âœ… Extracted from instruction, properly formatted as lowercase with underscores

### 4. **Reference Link** âœ… CORRECT
```json
"link": "https://hpvchemicals.oecd.org/ui/handler.axd?id=463ce644-e5c8-42e8-962d-3a917f32ab90"
```
**Analysis**: âœ… Correctly extracted URL from instruction

### 5. **Reference Title** âœ… CORRECT
```json
"title": "OECD SIDS MENTHOLS UNEP PUBLICATIONS"
```
**Analysis**: âœ… Used the source from instruction (not "ECHA Registration Dossier")

### 6. **Data Statement** âœ… CORRECT
```json
"data": ["Repeated dose toxicity study showed NOAEL of 200 mg/kg bw/day"]
```
**Analysis**: âœ… Mentioned 200, not 800 from examples

---

## âŒ What GPT-4o-mini Got WRONG (CHEATING):

### 1. **Experiment Target** âŒ COPIED FROM EXAMPLE
```json
"experiment_target": "Rats"
```
**Problem**: âš ï¸ This is DIRECTLY COPIED from the PETROLATUM example!
- **Not in instruction**: Your instruction for L-MENTHOL doesn't mention "Rats"
- **Source**: This is from Example 1 (PETROLATUM with Rats)
- **Should be**: `null` (since not specified in instruction)

**Evidence of cheating**: ğŸ”´ HIGH

---

### 2. **Study Duration** âŒ COPIED FROM EXAMPLE
```json
"study_duration": "90-day"
```
**Problem**: âš ï¸ This is DIRECTLY COPIED from the PETROLATUM example!
- **Not in instruction**: Your instruction for L-MENTHOL doesn't mention "90-day"
- **Source**: This is from Example 1 (PETROLATUM with 90-day study)
- **Should be**: `null` (since not specified in instruction)

**Evidence of cheating**: ğŸ”´ HIGH

---

### 3. **Type Field** âš ï¸ MINOR ERROR
```json
"type": "noael"
```
**Problem**: Should be uppercase "NOAEL" (as specified in examples and schema)
- **Expected**: `"type": "NOAEL"`
- **Got**: `"type": "noael"`

**Evidence of cheating**: ğŸŸ¡ LOW (likely just formatting inconsistency)

---

### 4. **Percutaneous Absorption** âš ï¸ QUESTIONABLE
```json
"percutaneous_absorption": [
  {
    "reference": {
      "title": "Expert Assessment",
      "link": null
    },
    "data": ["Dermal absorption estimated at 5% based on molecular properties"],
    "source": "expert",
    "statement": "Conservative estimate for safety assessment",
    "replaced": {...}
  }
]
```

**Problem**: This entire section is VERY similar to Example 2 (DAP update):
- âœ… Title "Expert Assessment" - Could be coincidence OR copied
- âœ… Statement "Conservative estimate for safety assessment" - EXACT MATCH to example!
- âš ï¸ "based on molecular properties" appears in the example

**Evidence of cheating**: ğŸŸ¡ MEDIUM (suspicious similarity, but could be model generating similar phrasing)

---

## ğŸ“Š Detailed Scoring:

| Field | Correct? | Score | Notes |
|-------|----------|-------|-------|
| INCI name | âœ… | 1.0/1 | Perfect |
| NOAEL value | âœ… | 1.0/1 | Used 200, not 800 |
| NOAEL unit | âœ… | 1.0/1 | Correct |
| NOAEL source | âœ… | 1.0/1 | Extracted from instruction |
| NOAEL experiment_target | âŒ | 0.0/1 | **COPIED "Rats" from example** |
| NOAEL study_duration | âŒ | 0.0/1 | **COPIED "90-day" from example** |
| NOAEL type | âš ï¸ | 0.5/1 | Wrong case |
| Reference title | âœ… | 1.0/1 | Correct |
| Reference link | âœ… | 1.0/1 | Correct |
| Data statement | âš ï¸ | 0.5/1 | Suspicious similarity |
| DAP value | âœ… | 0.5/0.5 | Correct (5%) |

**Total: 8.5/11.5 = 73.9%**

---

## ğŸ” Why This is Still Cheating:

Even though GPT-4o-mini got the **main value (200)** correct, it's still **copying optional fields** from the example:

1. **"Rats"** is nowhere in your L-MENTHOL instruction
2. **"90-day"** is nowhere in your L-MENTHOL instruction
3. These exact values appear in the PETROLATUM example

### Your Instruction for L-MENTHOL:
```
For L-MENTHOL:
- Set NOAEL to 200 mg/kg bw/day
- Source: OECD SIDS MENTHOLS UNEP PUBLICATIONS
- Reference: https://...
```

**What's mentioned**: Value (200), unit (mg/kg bw/day), source (OECD)
**What's NOT mentioned**: Experiment target, study duration

**Correct behavior**: Set unmention fields to `null`
**GPT-4o-mini's behavior**: Fill them with values from PETROLATUM example

---

## ğŸ’¡ Why GPT-4o-mini is Better (but still cheats):

### Compared to llama3.1:8b:
- âœ… **Main value extraction**: GPT-4o-mini correctly used 200 (llama might use 800)
- âœ… **Source extraction**: GPT-4o-mini correctly extracted OECD source
- âœ… **Reference handling**: GPT-4o-mini properly formatted the reference
- âŒ **Optional fields**: Still copying "Rats" and "90-day" from examples

### The Pattern:
```
llama3.1:8b      â†’ Copies EVERYTHING (value, target, duration)
GPT-4o-mini      â†’ Copies OPTIONAL FIELDS (target, duration) but gets main value right
GPT-4 (full)     â†’ Would likely set optional fields to null correctly
```

---

## ğŸ¯ Root Cause Analysis:

### Why is GPT-4o-mini still cheating?

**Hypothesis 1**: **Incomplete Instruction Following**
- Model reads: "Set NOAEL to 200 mg/kg bw/day"
- Model thinks: "Okay, value=200, unit=mg/kg bw/day"
- Model also thinks: "But what about experiment_target and study_duration?"
- Model sees example: "Oh, the example uses Rats and 90-day"
- Model decides: "I'll use those as reasonable defaults"

**Hypothesis 2**: **Pattern Completion Bias**
- GPT-4o-mini recognizes the NOAEL structure needs multiple fields
- Your instruction only provides 3/7 fields
- Model fills "gaps" using the most recent example (PETROLATUM)

**Hypothesis 3**: **Insufficient Negative Examples**
- Your prompt shows examples with ALL fields filled
- Model never sees an example where `experiment_target: null`
- Model assumes ALL fields should be populated

---

## âœ… How to Fix This for GPT-4o-mini:

### Solution 1: **Explicit Null Instructions** (RECOMMENDED)

Add this to your prompt:
```python
CRITICAL FIELD-FILLING RULES:
1. If instruction specifies a field value â†’ use that value
2. If instruction does NOT specify a field â†’ set to null
3. DO NOT fill missing fields with values from examples
4. Example: If instruction doesn't mention "experiment_target", use null (NOT "Rats")
5. Example: If instruction doesn't mention "study_duration", use null (NOT "90-day")
```

### Solution 2: **Add Sparse Example**

Add an example showing proper null handling:
```python
Example 4 - SPARSE DATA (shows proper null handling):
Input: "Set NOAEL to 300 mg/kg bw/day from WHO report"
Output:
{{
  "inci": "SUBSTANCE_X",
  "NOAEL": [
    {{
      "value": 300,
      "unit": "mg/kg bw/day",
      "source": "who",
      "type": "NOAEL",
      "experiment_target": null,  # â† Not specified, so null
      "study_duration": null,     # â† Not specified, so null
      "note": null                # â† Not specified, so null
    }}
  ]
}}
â†’ Notice: Only fills fields mentioned in instruction, rest are null!
```

### Solution 3: **Pre-fill Template with Nulls**

Modify your prompt generation:
```python
def _build_llm_prompt(json_data: dict, user_input: str, current_inci: str) -> str:
    # Add this section
    null_template = """
NOAEL Template (use this structure, fill ONLY mentioned fields):
{{
  "value": <from_instruction>,
  "unit": <from_instruction>,
  "source": <from_instruction>,
  "type": "NOAEL",
  "experiment_target": null,  # Only fill if mentioned
  "study_duration": null,     # Only fill if mentioned
  "note": null                # Only fill if mentioned
}}
"""
    
    return f"""
    {your_existing_prompt}
    
    {null_template}
    
    Now process the instruction...
    """
```

---

## ğŸ§ª Validation Test:

After fixing, your L-MENTHOL result should look like this:

```json
{
  "NOAEL": [
    {
      "note": null,                     // âœ… null (not specified)
      "unit": "mg/kg bw/day",           // âœ… from instruction
      "experiment_target": null,        // âœ… null (NOT "Rats")
      "source": "oecd_sids...",         // âœ… from instruction
      "type": "NOAEL",                  // âœ… correct
      "study_duration": null,           // âœ… null (NOT "90-day")
      "value": 200                      // âœ… from instruction
    }
  ]
}
```

---

## ğŸ“ˆ Comparison: Before vs After Fix

### BEFORE (Current Result):
```json
"experiment_target": "Rats",      // âŒ Copied from example
"study_duration": "90-day",       // âŒ Copied from example
"value": 200                      // âœ… Correct
```

### AFTER (Expected with Fix):
```json
"experiment_target": null,        // âœ… Null (not in instruction)
"study_duration": null,           // âœ… Null (not in instruction)
"value": 200                      // âœ… Correct
```

---

## ğŸ¯ Final Verdict:

**Current Result**: **6.5/10 - Partial Cheating**

**Positive**:
- âœ… Main value extraction works (200 vs 800)
- âœ… Source extraction works (OECD vs ECHA)
- âœ… Better than llama3.1:8b

**Negative**:
- âŒ Still copying optional fields ("Rats", "90-day")
- âŒ Not truly instruction-only
- âš ï¸ Would fail in production with sparse data

**Recommendation**: Implement **Solution 2** (add sparse example) + **Solution 1** (explicit null rules)

---

## ğŸ’¡ Key Takeaway:

> **Even GPT-4o-mini suffers from "example field completion bias"**
> 
> The model sees examples with ALL fields populated and assumes it should do the same.
> 
> **Fix**: Show examples with sparse data and explicit null-filling instructions.

---

## ğŸš€ Next Steps:

1. âœ… Acknowledge: GPT-4o-mini is BETTER than llama3.1:8b (got main values right)
2. âš ï¸ Recognize: Still has subtle cheating (optional field copying)
3. ğŸ”§ Fix: Add sparse example + null-filling rules to prompt
4. ğŸ§ª Test: Run test again and verify `experiment_target` and `study_duration` are null

Would you like me to create the fixed prompt with these improvements?
